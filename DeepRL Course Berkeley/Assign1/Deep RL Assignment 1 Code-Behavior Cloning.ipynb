{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep RL Assignment 1: Imitation Learning\n",
    "\n",
    "__[Starter Code](https://github.com/berkeleydeeprlcourse/homework/tree/master/hw1)__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import gym\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import tensorflow as tf\n",
    "import tf_util\n",
    "import load_policy\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation\n",
    "from sklearn.utils import shuffle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate roll-outs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "roll_outs = [\"Ant-v2\", \"HalfCheetah-v2\", \"Hopper-v2\", \"Humanoid-v2\", \"Reacher-v2\", \"Walker2d-v2\"]\n",
    "#roll_outs = [\"Hopper-v2\"]\n",
    "num_rollouts = 20;\n",
    "render = False;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading and building expert policy for Ant-v2\n",
      "obs (1, 111) (1, 111)\n",
      "Ant-v2 loaded and built\n",
      "returns [4770.287577910028, 4835.357651046034, 4825.587035960754, 4852.304003274105, 4784.8834799021515, 4552.636252745802, 4585.849507322293, 2355.5772964509724, 4664.178043039128, 4710.926928526234, 4668.690227514381, 4812.332008383825, 4766.633324025868, 4893.065891524669, 4834.5992607913495, 4683.787742630899, 2461.9049442401874, 4839.247704650443, 4666.345814550789, 4627.270886627383]\n",
      "mean return 4509.573279055865\n",
      "std of return 706.5844080982052\n",
      "loading and building expert policy for HalfCheetah-v2\n",
      "obs (1, 17) (1, 17)\n",
      "HalfCheetah-v2 loaded and built\n",
      "returns [4200.850132120267, 4129.352976808337, 4095.6153395645674, 4145.425097176482, 4193.860396908735, 4144.751966443285, 4115.864566071722, 4095.4784714263565, 4064.6759552449525, 4197.990465205169, 4134.952769848915, 4210.691976966783, 4041.9232784904316, 4211.146618891761, 4099.566715948844, 4113.147764701846, 4097.108485208171, 4172.104929118711, 4107.004471044998, 4118.508490846007]\n",
      "mean return 4134.501043401817\n",
      "std of return 48.07087381837846\n",
      "loading and building expert policy for Hopper-v2\n",
      "obs (1, 11) (1, 11)\n",
      "Hopper-v2 loaded and built\n",
      "returns [3778.0629309239544, 3783.8514709238093, 3783.0697631089274, 3780.9833478514947, 3773.351518932752, 3776.3237405116606, 3778.369006603628, 3769.511690883437, 3778.1206005561103, 3774.040948131926, 3781.7682761375354, 3782.6353259341686, 3781.560508249741, 3781.5893738015493, 3782.4716051878545, 3774.266398806135, 3783.5866094127095, 3773.700260139911, 3780.2059015082314, 3775.966902757992]\n",
      "mean return 3778.671809018177\n",
      "std of return 4.037287842582274\n",
      "loading and building expert policy for Humanoid-v2\n",
      "obs (1, 376) (1, 376)\n",
      "Humanoid-v2 loaded and built\n",
      "returns [10561.39457314665, 10750.44989440128, 10618.959809103044, 10658.324726269513, 10584.316613486219, 10703.918640305286, 10655.944708868374, 10702.86052338189, 5414.246355046286, 10697.23946805283, 10585.32577307077, 10707.810755014816, 10699.912384232957, 10724.749593364295, 10660.081226690456, 752.0228682554605, 10722.91799881681, 10713.008252992435, 8116.3809437093805, 10742.309643242144]\n",
      "mean return 9788.608737572544\n",
      "std of return 2418.958090200169\n",
      "loading and building expert policy for Reacher-v2\n",
      "obs (1, 11) (1, 11)\n",
      "Reacher-v2 loaded and built\n",
      "returns [-3.595156261065556, -2.203547664590345, -0.7268780954173397, -1.437736617428089, -3.9936125559293845, -3.6030042271851364, -6.34976671797748, -3.8264166298205753, -2.3210810357191023, -3.9263926309464656, -5.246608672322621, -3.8723183040088696, -4.356753808365299, -2.431121778244806, -3.8914088422173503, -5.564899072026625, -4.6081354279705895, -1.120492940609935, -2.7738309775020165, -5.5249696755402615]\n",
      "mean return -3.5687065967443927\n",
      "std of return 1.4931987471897301\n",
      "loading and building expert policy for Walker2d-v2\n",
      "obs (1, 17) (1, 17)\n",
      "Walker2d-v2 loaded and built\n",
      "returns [5439.278899763195, 5562.000203504111, 5486.483564775653, 5572.6441831774555, 5535.492050781467, 5533.193020513076, 5542.74164272037, 5506.403177494072, 5544.543078552946, 5443.853650899058, 5577.530676444442, 5495.182946514102, 5618.284405345204, 5585.937545876012, 5495.704061516094, 5589.049150524666, 5442.195490784944, 5554.50733095564, 5562.324944575491, 5454.503588373925]\n",
      "mean return 5527.092680654596\n",
      "std of return 52.58426670450712\n",
      "Roll-outs generated and stored in data folder.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for roll_out in roll_outs:\n",
    "    expert = \"experts/\" + roll_out + \".pkl\"\n",
    "    print(\"loading and building expert policy for \" + roll_out)\n",
    "    policy_fn = load_policy.load_policy(expert)\n",
    "    print(roll_out + \" loaded and built\")\n",
    "\n",
    "    with tf.Session():\n",
    "        tf_util.initialize()\n",
    "\n",
    "        env = gym.make(roll_out)\n",
    "        # max_steps = env.spec.timestep_limit\n",
    "        max_steps = env.spec.tags.get('wrapper_config.TimeLimit.max_episode_steps')\n",
    "\n",
    "        returns = []\n",
    "        observations = []\n",
    "        actions = []\n",
    "        step_count = []\n",
    "        \n",
    "        for i in range(num_rollouts):\n",
    "            # print('iter', i)\n",
    "            obs = env.reset()\n",
    "            done = False\n",
    "            totalr = 0.\n",
    "            steps = 0\n",
    "            while not done:\n",
    "                action = policy_fn(obs[None,:])\n",
    "                observations.append(obs)\n",
    "                actions.append(action)\n",
    "                obs, r, done, _ = env.step(action)\n",
    "                totalr += r\n",
    "                steps += 1\n",
    "                if render:\n",
    "                    env.render()\n",
    "                # if steps % 100 == 0: print(\"%i/%i\"%(steps, max_steps))\n",
    "                if steps >= max_steps:\n",
    "                    break\n",
    "            returns.append(totalr)\n",
    "            step_count.append(steps)\n",
    "\n",
    "        print('returns', returns)\n",
    "        print('mean return', np.mean(returns))\n",
    "        print('std of return', np.std(returns))\n",
    "\n",
    "        expert_data = {'observations': np.array(observations),\n",
    "                       'actions': np.array(actions),\n",
    "                       'returns': np.array(returns),\n",
    "                       'steps': np.array(step_count)\n",
    "                      }\n",
    "        \n",
    "# if the expert_data directory doesn't exist, make it\n",
    "output_dir = 'expert_data'\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)   \n",
    "    \n",
    "# store the roll outs in expert_data folder    \n",
    "for roll_out in roll_outs:\n",
    "        with open(os.path.join('expert_data', roll_out + '.pkl'), 'wb') as f:\n",
    "            pickle.dump(expert_data, f, pickle.HIGHEST_PROTOCOL)\n",
    "            \n",
    "print(\"Roll-outs generated and stored in data folder.\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple Sequential Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------------------------------------------------------------------\n",
      "Ant-v2 Policy Data Loaded\n",
      "Creating model for... Ant-v2\n",
      "---------------------------------------------------------------------------------------------------------\n",
      "Fitting model for... Ant-v2\n",
      "Train on 18000 samples, validate on 2000 samples\n",
      "Epoch 1/50\n",
      " - 2s - loss: 0.9867 - mean_absolute_error: 0.7781 - val_loss: 0.5428 - val_mean_absolute_error: 0.5749\n",
      "Epoch 2/50\n",
      " - 1s - loss: 0.4280 - mean_absolute_error: 0.5099 - val_loss: 0.3538 - val_mean_absolute_error: 0.4632\n",
      "Epoch 3/50\n",
      " - 1s - loss: 0.3206 - mean_absolute_error: 0.4433 - val_loss: 0.2896 - val_mean_absolute_error: 0.4214\n",
      "Epoch 4/50\n",
      " - 2s - loss: 0.2713 - mean_absolute_error: 0.4088 - val_loss: 0.2529 - val_mean_absolute_error: 0.3947\n",
      "Epoch 5/50\n",
      " - 1s - loss: 0.2467 - mean_absolute_error: 0.3901 - val_loss: 0.2373 - val_mean_absolute_error: 0.3808\n",
      "Epoch 6/50\n",
      " - 1s - loss: 0.2315 - mean_absolute_error: 0.3783 - val_loss: 0.2189 - val_mean_absolute_error: 0.3670\n",
      "Epoch 7/50\n",
      " - 1s - loss: 0.2189 - mean_absolute_error: 0.3686 - val_loss: 0.2106 - val_mean_absolute_error: 0.3611\n",
      "Epoch 8/50\n",
      " - 1s - loss: 0.2103 - mean_absolute_error: 0.3619 - val_loss: 0.2028 - val_mean_absolute_error: 0.3574\n",
      "Epoch 9/50\n",
      " - 1s - loss: 0.2033 - mean_absolute_error: 0.3568 - val_loss: 0.1976 - val_mean_absolute_error: 0.3529\n",
      "Epoch 10/50\n",
      " - 1s - loss: 0.1987 - mean_absolute_error: 0.3530 - val_loss: 0.1930 - val_mean_absolute_error: 0.3470\n",
      "Epoch 11/50\n",
      " - 1s - loss: 0.1956 - mean_absolute_error: 0.3502 - val_loss: 0.1911 - val_mean_absolute_error: 0.3459\n",
      "Epoch 12/50\n",
      " - 1s - loss: 0.1931 - mean_absolute_error: 0.3480 - val_loss: 0.1879 - val_mean_absolute_error: 0.3439\n",
      "Epoch 13/50\n",
      " - 1s - loss: 0.1913 - mean_absolute_error: 0.3466 - val_loss: 0.1872 - val_mean_absolute_error: 0.3417\n",
      "Epoch 14/50\n",
      " - 1s - loss: 0.1900 - mean_absolute_error: 0.3454 - val_loss: 0.1868 - val_mean_absolute_error: 0.3418\n",
      "Epoch 15/50\n",
      " - 1s - loss: 0.1887 - mean_absolute_error: 0.3443 - val_loss: 0.1864 - val_mean_absolute_error: 0.3421\n",
      "Epoch 16/50\n",
      " - 1s - loss: 0.1880 - mean_absolute_error: 0.3437 - val_loss: 0.1842 - val_mean_absolute_error: 0.3399\n",
      "Epoch 17/50\n",
      " - 1s - loss: 0.1872 - mean_absolute_error: 0.3428 - val_loss: 0.1834 - val_mean_absolute_error: 0.3394\n",
      "Epoch 18/50\n",
      " - 1s - loss: 0.1867 - mean_absolute_error: 0.3424 - val_loss: 0.1828 - val_mean_absolute_error: 0.3390\n",
      "Epoch 19/50\n",
      " - 1s - loss: 0.1858 - mean_absolute_error: 0.3415 - val_loss: 0.1834 - val_mean_absolute_error: 0.3399\n",
      "Epoch 20/50\n",
      " - 1s - loss: 0.1853 - mean_absolute_error: 0.3410 - val_loss: 0.1816 - val_mean_absolute_error: 0.3369\n",
      "Epoch 21/50\n",
      " - 1s - loss: 0.1847 - mean_absolute_error: 0.3403 - val_loss: 0.1809 - val_mean_absolute_error: 0.3361\n",
      "Epoch 22/50\n",
      " - 1s - loss: 0.1847 - mean_absolute_error: 0.3405 - val_loss: 0.1816 - val_mean_absolute_error: 0.3365\n",
      "Epoch 23/50\n",
      " - 1s - loss: 0.1845 - mean_absolute_error: 0.3399 - val_loss: 0.1809 - val_mean_absolute_error: 0.3367\n",
      "Epoch 24/50\n",
      " - 1s - loss: 0.1839 - mean_absolute_error: 0.3397 - val_loss: 0.1807 - val_mean_absolute_error: 0.3376\n",
      "Epoch 25/50\n",
      " - 2s - loss: 0.1836 - mean_absolute_error: 0.3392 - val_loss: 0.1806 - val_mean_absolute_error: 0.3367\n",
      "Epoch 26/50\n",
      " - 1s - loss: 0.1835 - mean_absolute_error: 0.3391 - val_loss: 0.1796 - val_mean_absolute_error: 0.3341\n",
      "Epoch 27/50\n",
      " - 1s - loss: 0.1832 - mean_absolute_error: 0.3390 - val_loss: 0.1801 - val_mean_absolute_error: 0.3363\n",
      "Epoch 28/50\n",
      " - 2s - loss: 0.1829 - mean_absolute_error: 0.3386 - val_loss: 0.1823 - val_mean_absolute_error: 0.3388\n",
      "Epoch 29/50\n",
      " - 2s - loss: 0.1829 - mean_absolute_error: 0.3387 - val_loss: 0.1798 - val_mean_absolute_error: 0.3347\n",
      "Epoch 30/50\n",
      " - 2s - loss: 0.1828 - mean_absolute_error: 0.3387 - val_loss: 0.1797 - val_mean_absolute_error: 0.3355\n",
      "Epoch 31/50\n",
      " - 1s - loss: 0.1821 - mean_absolute_error: 0.3380 - val_loss: 0.1798 - val_mean_absolute_error: 0.3358\n",
      "Epoch 32/50\n",
      " - 1s - loss: 0.1823 - mean_absolute_error: 0.3381 - val_loss: 0.1787 - val_mean_absolute_error: 0.3338\n",
      "Epoch 33/50\n",
      " - 1s - loss: 0.1820 - mean_absolute_error: 0.3379 - val_loss: 0.1794 - val_mean_absolute_error: 0.3343\n",
      "Epoch 34/50\n",
      " - 1s - loss: 0.1819 - mean_absolute_error: 0.3379 - val_loss: 0.1795 - val_mean_absolute_error: 0.3364\n",
      "Epoch 35/50\n",
      " - 1s - loss: 0.1817 - mean_absolute_error: 0.3377 - val_loss: 0.1785 - val_mean_absolute_error: 0.3333\n",
      "Epoch 36/50\n",
      " - 1s - loss: 0.1816 - mean_absolute_error: 0.3375 - val_loss: 0.1783 - val_mean_absolute_error: 0.3341\n",
      "Epoch 37/50\n",
      " - 1s - loss: 0.1814 - mean_absolute_error: 0.3373 - val_loss: 0.1783 - val_mean_absolute_error: 0.3339\n",
      "Epoch 38/50\n",
      " - 1s - loss: 0.1812 - mean_absolute_error: 0.3372 - val_loss: 0.1778 - val_mean_absolute_error: 0.3337\n",
      "Epoch 39/50\n",
      " - 1s - loss: 0.1812 - mean_absolute_error: 0.3372 - val_loss: 0.1778 - val_mean_absolute_error: 0.3328\n",
      "Epoch 40/50\n",
      " - 1s - loss: 0.1811 - mean_absolute_error: 0.3372 - val_loss: 0.1791 - val_mean_absolute_error: 0.3341\n",
      "Epoch 41/50\n",
      " - 1s - loss: 0.1808 - mean_absolute_error: 0.3371 - val_loss: 0.1780 - val_mean_absolute_error: 0.3351\n",
      "Epoch 42/50\n",
      " - 1s - loss: 0.1809 - mean_absolute_error: 0.3371 - val_loss: 0.1793 - val_mean_absolute_error: 0.3355\n",
      "Epoch 43/50\n",
      " - 1s - loss: 0.1807 - mean_absolute_error: 0.3368 - val_loss: 0.1781 - val_mean_absolute_error: 0.3335\n",
      "Epoch 44/50\n",
      " - 1s - loss: 0.1806 - mean_absolute_error: 0.3366 - val_loss: 0.1772 - val_mean_absolute_error: 0.3329\n",
      "Epoch 45/50\n",
      " - 1s - loss: 0.1803 - mean_absolute_error: 0.3366 - val_loss: 0.1778 - val_mean_absolute_error: 0.3341\n",
      "Epoch 46/50\n",
      " - 1s - loss: 0.1803 - mean_absolute_error: 0.3367 - val_loss: 0.1772 - val_mean_absolute_error: 0.3327\n",
      "Epoch 47/50\n",
      " - 1s - loss: 0.1805 - mean_absolute_error: 0.3368 - val_loss: 0.1775 - val_mean_absolute_error: 0.3346\n",
      "Epoch 48/50\n",
      " - 1s - loss: 0.1802 - mean_absolute_error: 0.3364 - val_loss: 0.1765 - val_mean_absolute_error: 0.3321\n",
      "Epoch 49/50\n",
      " - 1s - loss: 0.1803 - mean_absolute_error: 0.3366 - val_loss: 0.1768 - val_mean_absolute_error: 0.3325\n",
      "Epoch 50/50\n",
      " - 1s - loss: 0.1802 - mean_absolute_error: 0.3366 - val_loss: 0.1762 - val_mean_absolute_error: 0.3321\n",
      "---------------------------------------------------------------------------------------------------------\n",
      "Running model for... Ant-v2\n",
      "returns [1032.868438285445, 1032.041632185553, 1032.289320588796, 1030.9851336019588, 1031.92886932149, 1032.415986464212, 1031.8543532327503, 1032.6509762841818, 1031.543306023079, 1032.2364265771346, 1031.5227406301758, 1031.8662642496024, 1032.3219653975084, 1031.8166309276376, 1031.7615930655816, 1032.0488149179148, 1031.4686972065035, 1031.9109512655175, 1031.7338453143159, 1031.8699553949518]\n",
      "mean return 1031.9567950467153\n",
      "std of return 0.42070953036837655\n",
      "---------------------------------------------------------------------------------------------------------\n",
      "Comparing Walker2d-v2 to expert.\n",
      "Summary statistics for: Walker2d-v2\n",
      "                     expert      predict\n",
      "mean reward     5527.092681  1031.956795\n",
      "std reward        52.584267     0.420710\n",
      "% full rollout     1.000000     1.000000\n",
      "---------------------------------------------------------------------------------------------------------\n",
      "HalfCheetah-v2 Policy Data Loaded\n",
      "Creating model for... HalfCheetah-v2\n",
      "---------------------------------------------------------------------------------------------------------\n",
      "Fitting model for... HalfCheetah-v2\n",
      "Train on 18000 samples, validate on 2000 samples\n",
      "Epoch 1/50\n",
      " - 2s - loss: 1.1920 - mean_absolute_error: 0.8567 - val_loss: 0.9316 - val_mean_absolute_error: 0.7597\n",
      "Epoch 2/50\n",
      " - 1s - loss: 0.8245 - mean_absolute_error: 0.7086 - val_loss: 0.7480 - val_mean_absolute_error: 0.6674\n",
      "Epoch 3/50\n",
      " - 1s - loss: 0.6840 - mean_absolute_error: 0.6332 - val_loss: 0.6189 - val_mean_absolute_error: 0.5960\n",
      "Epoch 4/50\n",
      " - 1s - loss: 0.5890 - mean_absolute_error: 0.5767 - val_loss: 0.5602 - val_mean_absolute_error: 0.5607\n",
      "Epoch 5/50\n",
      " - 1s - loss: 0.5529 - mean_absolute_error: 0.5550 - val_loss: 0.5374 - val_mean_absolute_error: 0.5461\n",
      "Epoch 6/50\n",
      " - 1s - loss: 0.5398 - mean_absolute_error: 0.5466 - val_loss: 0.5301 - val_mean_absolute_error: 0.5418\n",
      "Epoch 7/50\n",
      " - 1s - loss: 0.5346 - mean_absolute_error: 0.5440 - val_loss: 0.5230 - val_mean_absolute_error: 0.5384\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/50\n",
      " - 1s - loss: 0.5273 - mean_absolute_error: 0.5384 - val_loss: 0.5176 - val_mean_absolute_error: 0.5338\n",
      "Epoch 9/50\n",
      " - 1s - loss: 0.5242 - mean_absolute_error: 0.5360 - val_loss: 0.5154 - val_mean_absolute_error: 0.5316\n",
      "Epoch 10/50\n",
      " - 1s - loss: 0.5219 - mean_absolute_error: 0.5354 - val_loss: 0.5126 - val_mean_absolute_error: 0.5308\n",
      "Epoch 11/50\n",
      " - 1s - loss: 0.5189 - mean_absolute_error: 0.5337 - val_loss: 0.5109 - val_mean_absolute_error: 0.5300\n",
      "Epoch 12/50\n",
      " - 1s - loss: 0.5169 - mean_absolute_error: 0.5328 - val_loss: 0.5096 - val_mean_absolute_error: 0.5292\n",
      "Epoch 13/50\n",
      " - 1s - loss: 0.5155 - mean_absolute_error: 0.5320 - val_loss: 0.5084 - val_mean_absolute_error: 0.5295\n",
      "Epoch 14/50\n",
      " - 1s - loss: 0.5140 - mean_absolute_error: 0.5311 - val_loss: 0.5080 - val_mean_absolute_error: 0.5300\n",
      "Epoch 15/50\n",
      " - 1s - loss: 0.5133 - mean_absolute_error: 0.5308 - val_loss: 0.5058 - val_mean_absolute_error: 0.5266\n",
      "Epoch 16/50\n",
      " - 1s - loss: 0.5126 - mean_absolute_error: 0.5303 - val_loss: 0.5053 - val_mean_absolute_error: 0.5275\n",
      "Epoch 17/50\n",
      " - 1s - loss: 0.5120 - mean_absolute_error: 0.5300 - val_loss: 0.5052 - val_mean_absolute_error: 0.5282\n",
      "Epoch 18/50\n",
      " - 1s - loss: 0.5112 - mean_absolute_error: 0.5295 - val_loss: 0.5044 - val_mean_absolute_error: 0.5264\n",
      "Epoch 19/50\n",
      " - 1s - loss: 0.5108 - mean_absolute_error: 0.5292 - val_loss: 0.5046 - val_mean_absolute_error: 0.5258\n",
      "Epoch 20/50\n",
      " - 1s - loss: 0.5104 - mean_absolute_error: 0.5289 - val_loss: 0.5038 - val_mean_absolute_error: 0.5263\n",
      "Epoch 21/50\n",
      " - 1s - loss: 0.5099 - mean_absolute_error: 0.5285 - val_loss: 0.5037 - val_mean_absolute_error: 0.5256\n",
      "Epoch 22/50\n",
      " - 1s - loss: 0.5097 - mean_absolute_error: 0.5282 - val_loss: 0.5038 - val_mean_absolute_error: 0.5263\n",
      "Epoch 23/50\n",
      " - 1s - loss: 0.5094 - mean_absolute_error: 0.5279 - val_loss: 0.5032 - val_mean_absolute_error: 0.5270\n",
      "Epoch 24/50\n",
      " - 1s - loss: 0.5091 - mean_absolute_error: 0.5279 - val_loss: 0.5036 - val_mean_absolute_error: 0.5264\n",
      "Epoch 25/50\n",
      " - 1s - loss: 0.5090 - mean_absolute_error: 0.5278 - val_loss: 0.5029 - val_mean_absolute_error: 0.5236\n",
      "Epoch 26/50\n",
      " - 1s - loss: 0.5089 - mean_absolute_error: 0.5275 - val_loss: 0.5025 - val_mean_absolute_error: 0.5246\n",
      "Epoch 27/50\n",
      " - 1s - loss: 0.5088 - mean_absolute_error: 0.5275 - val_loss: 0.5032 - val_mean_absolute_error: 0.5241\n",
      "Epoch 28/50\n",
      " - 1s - loss: 0.5087 - mean_absolute_error: 0.5273 - val_loss: 0.5023 - val_mean_absolute_error: 0.5248\n",
      "Epoch 29/50\n",
      " - 1s - loss: 0.5085 - mean_absolute_error: 0.5271 - val_loss: 0.5029 - val_mean_absolute_error: 0.5250\n",
      "Epoch 30/50\n",
      " - 1s - loss: 0.5085 - mean_absolute_error: 0.5270 - val_loss: 0.5028 - val_mean_absolute_error: 0.5246\n",
      "Epoch 31/50\n",
      " - 1s - loss: 0.5083 - mean_absolute_error: 0.5271 - val_loss: 0.5033 - val_mean_absolute_error: 0.5268\n",
      "Epoch 32/50\n",
      " - 1s - loss: 0.5083 - mean_absolute_error: 0.5271 - val_loss: 0.5019 - val_mean_absolute_error: 0.5251\n",
      "Epoch 33/50\n",
      " - 1s - loss: 0.5083 - mean_absolute_error: 0.5270 - val_loss: 0.5021 - val_mean_absolute_error: 0.5253\n",
      "Epoch 34/50\n",
      " - 1s - loss: 0.5082 - mean_absolute_error: 0.5270 - val_loss: 0.5022 - val_mean_absolute_error: 0.5261\n",
      "Epoch 35/50\n",
      " - 1s - loss: 0.5081 - mean_absolute_error: 0.5268 - val_loss: 0.5012 - val_mean_absolute_error: 0.5232\n",
      "Epoch 36/50\n",
      " - 1s - loss: 0.5081 - mean_absolute_error: 0.5268 - val_loss: 0.5031 - val_mean_absolute_error: 0.5268\n",
      "Epoch 37/50\n",
      " - 1s - loss: 0.5079 - mean_absolute_error: 0.5268 - val_loss: 0.5017 - val_mean_absolute_error: 0.5245\n",
      "Epoch 38/50\n",
      " - 1s - loss: 0.5078 - mean_absolute_error: 0.5266 - val_loss: 0.5022 - val_mean_absolute_error: 0.5228\n",
      "Epoch 39/50\n",
      " - 1s - loss: 0.5078 - mean_absolute_error: 0.5266 - val_loss: 0.5021 - val_mean_absolute_error: 0.5246\n",
      "Epoch 40/50\n",
      " - 1s - loss: 0.5077 - mean_absolute_error: 0.5265 - val_loss: 0.5021 - val_mean_absolute_error: 0.5233\n",
      "Epoch 41/50\n",
      " - 1s - loss: 0.5078 - mean_absolute_error: 0.5266 - val_loss: 0.5019 - val_mean_absolute_error: 0.5254\n",
      "Epoch 42/50\n",
      " - 1s - loss: 0.5078 - mean_absolute_error: 0.5266 - val_loss: 0.5013 - val_mean_absolute_error: 0.5235\n",
      "Epoch 43/50\n",
      " - 1s - loss: 0.5077 - mean_absolute_error: 0.5265 - val_loss: 0.5018 - val_mean_absolute_error: 0.5241\n",
      "Epoch 44/50\n",
      " - 1s - loss: 0.5076 - mean_absolute_error: 0.5265 - val_loss: 0.5019 - val_mean_absolute_error: 0.5237\n",
      "Epoch 45/50\n",
      " - 1s - loss: 0.5077 - mean_absolute_error: 0.5266 - val_loss: 0.5011 - val_mean_absolute_error: 0.5235\n",
      "Epoch 46/50\n",
      " - 1s - loss: 0.5075 - mean_absolute_error: 0.5263 - val_loss: 0.5020 - val_mean_absolute_error: 0.5250\n",
      "Epoch 47/50\n",
      " - 1s - loss: 0.5075 - mean_absolute_error: 0.5263 - val_loss: 0.5017 - val_mean_absolute_error: 0.5232\n",
      "Epoch 48/50\n",
      " - 1s - loss: 0.5074 - mean_absolute_error: 0.5263 - val_loss: 0.5015 - val_mean_absolute_error: 0.5242\n",
      "Epoch 49/50\n",
      " - 1s - loss: 0.5074 - mean_absolute_error: 0.5263 - val_loss: 0.5016 - val_mean_absolute_error: 0.5240\n",
      "Epoch 50/50\n",
      " - 1s - loss: 0.5074 - mean_absolute_error: 0.5264 - val_loss: 0.5016 - val_mean_absolute_error: 0.5236\n",
      "---------------------------------------------------------------------------------------------------------\n",
      "Running model for... HalfCheetah-v2\n",
      "returns [999.8729575587384, 1461.1876550089244, 1392.172402072112, 949.4247972682205, 933.3949027771108, 1538.3394652332574, 915.4908272991943, 895.8083652166385, 928.0799137596464, 965.1963760362243, 2257.2263732488564, 1086.1757389803802, 1332.2747570444908, 995.1179883750016, 1522.432122078062, 2026.6291745797507, 942.1779022288337, 1530.1764808484631, 1326.8384310487472, 1314.7535502680212]\n",
      "mean return 1265.6385090465335\n",
      "std of return 373.6377301463089\n",
      "---------------------------------------------------------------------------------------------------------\n",
      "Comparing Walker2d-v2 to expert.\n",
      "Summary statistics for: Walker2d-v2\n",
      "                     expert      predict\n",
      "mean reward     5527.092681  1265.638509\n",
      "std reward        52.584267   373.637730\n",
      "% full rollout     1.000000     0.576400\n",
      "---------------------------------------------------------------------------------------------------------\n",
      "Hopper-v2 Policy Data Loaded\n",
      "Creating model for... Hopper-v2\n",
      "---------------------------------------------------------------------------------------------------------\n",
      "Fitting model for... Hopper-v2\n",
      "Train on 18000 samples, validate on 2000 samples\n",
      "Epoch 1/50\n",
      " - 2s - loss: 1.0348 - mean_absolute_error: 0.7935 - val_loss: 0.7191 - val_mean_absolute_error: 0.6652\n",
      "Epoch 2/50\n",
      " - 1s - loss: 0.6407 - mean_absolute_error: 0.6271 - val_loss: 0.5894 - val_mean_absolute_error: 0.5987\n",
      "Epoch 3/50\n",
      " - 1s - loss: 0.5468 - mean_absolute_error: 0.5737 - val_loss: 0.5190 - val_mean_absolute_error: 0.5566\n",
      "Epoch 4/50\n",
      " - 1s - loss: 0.4040 - mean_absolute_error: 0.4748 - val_loss: 0.3315 - val_mean_absolute_error: 0.4203\n",
      "Epoch 5/50\n",
      " - 1s - loss: 0.2931 - mean_absolute_error: 0.3953 - val_loss: 0.2696 - val_mean_absolute_error: 0.3774\n",
      "Epoch 6/50\n",
      " - 1s - loss: 0.2500 - mean_absolute_error: 0.3681 - val_loss: 0.2376 - val_mean_absolute_error: 0.3625\n",
      "Epoch 7/50\n",
      " - 1s - loss: 0.2272 - mean_absolute_error: 0.3587 - val_loss: 0.2208 - val_mean_absolute_error: 0.3571\n",
      "Epoch 8/50\n",
      " - 1s - loss: 0.2144 - mean_absolute_error: 0.3546 - val_loss: 0.2126 - val_mean_absolute_error: 0.3570\n",
      "Epoch 9/50\n",
      " - 1s - loss: 0.2064 - mean_absolute_error: 0.3522 - val_loss: 0.2046 - val_mean_absolute_error: 0.3528\n",
      "Epoch 10/50\n",
      " - 1s - loss: 0.2009 - mean_absolute_error: 0.3504 - val_loss: 0.1994 - val_mean_absolute_error: 0.3511\n",
      "Epoch 11/50\n",
      " - 1s - loss: 0.1977 - mean_absolute_error: 0.3494 - val_loss: 0.1958 - val_mean_absolute_error: 0.3496\n",
      "Epoch 12/50\n",
      " - 1s - loss: 0.1947 - mean_absolute_error: 0.3479 - val_loss: 0.1942 - val_mean_absolute_error: 0.3498\n",
      "Epoch 13/50\n",
      " - 1s - loss: 0.1929 - mean_absolute_error: 0.3472 - val_loss: 0.1909 - val_mean_absolute_error: 0.3465\n",
      "Epoch 14/50\n",
      " - 1s - loss: 0.1913 - mean_absolute_error: 0.3462 - val_loss: 0.1894 - val_mean_absolute_error: 0.3466\n",
      "Epoch 15/50\n",
      " - 1s - loss: 0.1899 - mean_absolute_error: 0.3454 - val_loss: 0.1889 - val_mean_absolute_error: 0.3459\n",
      "Epoch 16/50\n",
      " - 1s - loss: 0.1886 - mean_absolute_error: 0.3444 - val_loss: 0.1877 - val_mean_absolute_error: 0.3449\n",
      "Epoch 17/50\n",
      " - 1s - loss: 0.1879 - mean_absolute_error: 0.3439 - val_loss: 0.1871 - val_mean_absolute_error: 0.3454\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18/50\n",
      " - 1s - loss: 0.1870 - mean_absolute_error: 0.3430 - val_loss: 0.1887 - val_mean_absolute_error: 0.3453\n",
      "Epoch 19/50\n",
      " - 1s - loss: 0.1862 - mean_absolute_error: 0.3425 - val_loss: 0.1875 - val_mean_absolute_error: 0.3446\n",
      "Epoch 20/50\n",
      " - 1s - loss: 0.1860 - mean_absolute_error: 0.3422 - val_loss: 0.1847 - val_mean_absolute_error: 0.3407\n",
      "Epoch 21/50\n",
      " - 1s - loss: 0.1851 - mean_absolute_error: 0.3413 - val_loss: 0.1844 - val_mean_absolute_error: 0.3421\n",
      "Epoch 22/50\n",
      " - 1s - loss: 0.1847 - mean_absolute_error: 0.3412 - val_loss: 0.1836 - val_mean_absolute_error: 0.3412\n",
      "Epoch 23/50\n",
      " - 1s - loss: 0.1843 - mean_absolute_error: 0.3408 - val_loss: 0.1841 - val_mean_absolute_error: 0.3412\n",
      "Epoch 24/50\n",
      " - 1s - loss: 0.1841 - mean_absolute_error: 0.3407 - val_loss: 0.1836 - val_mean_absolute_error: 0.3412\n",
      "Epoch 25/50\n",
      " - 1s - loss: 0.1836 - mean_absolute_error: 0.3401 - val_loss: 0.1832 - val_mean_absolute_error: 0.3397\n",
      "Epoch 26/50\n",
      " - 1s - loss: 0.1833 - mean_absolute_error: 0.3399 - val_loss: 0.1832 - val_mean_absolute_error: 0.3407\n",
      "Epoch 27/50\n",
      " - 1s - loss: 0.1829 - mean_absolute_error: 0.3394 - val_loss: 0.1818 - val_mean_absolute_error: 0.3391\n",
      "Epoch 28/50\n",
      " - 1s - loss: 0.1829 - mean_absolute_error: 0.3395 - val_loss: 0.1811 - val_mean_absolute_error: 0.3387\n",
      "Epoch 29/50\n",
      " - 1s - loss: 0.1824 - mean_absolute_error: 0.3389 - val_loss: 0.1815 - val_mean_absolute_error: 0.3387\n",
      "Epoch 30/50\n",
      " - 1s - loss: 0.1822 - mean_absolute_error: 0.3387 - val_loss: 0.1810 - val_mean_absolute_error: 0.3390\n",
      "Epoch 31/50\n",
      " - 1s - loss: 0.1820 - mean_absolute_error: 0.3385 - val_loss: 0.1809 - val_mean_absolute_error: 0.3379\n",
      "Epoch 32/50\n",
      " - 1s - loss: 0.1820 - mean_absolute_error: 0.3388 - val_loss: 0.1814 - val_mean_absolute_error: 0.3396\n",
      "Epoch 33/50\n",
      " - 1s - loss: 0.1815 - mean_absolute_error: 0.3381 - val_loss: 0.1818 - val_mean_absolute_error: 0.3386\n",
      "Epoch 34/50\n",
      " - 1s - loss: 0.1815 - mean_absolute_error: 0.3381 - val_loss: 0.1811 - val_mean_absolute_error: 0.3385\n",
      "Epoch 35/50\n",
      " - 1s - loss: 0.1815 - mean_absolute_error: 0.3382 - val_loss: 0.1809 - val_mean_absolute_error: 0.3376\n",
      "Epoch 36/50\n",
      " - 1s - loss: 0.1814 - mean_absolute_error: 0.3380 - val_loss: 0.1806 - val_mean_absolute_error: 0.3385\n",
      "Epoch 37/50\n",
      " - 1s - loss: 0.1810 - mean_absolute_error: 0.3376 - val_loss: 0.1807 - val_mean_absolute_error: 0.3373\n",
      "Epoch 38/50\n",
      " - 1s - loss: 0.1809 - mean_absolute_error: 0.3375 - val_loss: 0.1802 - val_mean_absolute_error: 0.3370\n",
      "Epoch 39/50\n",
      " - 1s - loss: 0.1808 - mean_absolute_error: 0.3373 - val_loss: 0.1818 - val_mean_absolute_error: 0.3372\n",
      "Epoch 40/50\n",
      " - 1s - loss: 0.1807 - mean_absolute_error: 0.3371 - val_loss: 0.1800 - val_mean_absolute_error: 0.3380\n",
      "Epoch 41/50\n",
      " - 1s - loss: 0.1807 - mean_absolute_error: 0.3373 - val_loss: 0.1794 - val_mean_absolute_error: 0.3371\n",
      "Epoch 42/50\n",
      " - 1s - loss: 0.1805 - mean_absolute_error: 0.3370 - val_loss: 0.1803 - val_mean_absolute_error: 0.3371\n",
      "Epoch 43/50\n",
      " - 1s - loss: 0.1804 - mean_absolute_error: 0.3369 - val_loss: 0.1803 - val_mean_absolute_error: 0.3386\n",
      "Epoch 44/50\n",
      " - 1s - loss: 0.1805 - mean_absolute_error: 0.3370 - val_loss: 0.1798 - val_mean_absolute_error: 0.3386\n",
      "Epoch 45/50\n",
      " - 1s - loss: 0.1802 - mean_absolute_error: 0.3368 - val_loss: 0.1799 - val_mean_absolute_error: 0.3373\n",
      "Epoch 46/50\n",
      " - 1s - loss: 0.1801 - mean_absolute_error: 0.3367 - val_loss: 0.1787 - val_mean_absolute_error: 0.3365\n",
      "Epoch 47/50\n",
      " - 1s - loss: 0.1799 - mean_absolute_error: 0.3364 - val_loss: 0.1792 - val_mean_absolute_error: 0.3368\n",
      "Epoch 48/50\n",
      " - 1s - loss: 0.1800 - mean_absolute_error: 0.3365 - val_loss: 0.1805 - val_mean_absolute_error: 0.3367\n",
      "Epoch 49/50\n",
      " - 1s - loss: 0.1798 - mean_absolute_error: 0.3364 - val_loss: 0.1790 - val_mean_absolute_error: 0.3363\n",
      "Epoch 50/50\n",
      " - 1s - loss: 0.1798 - mean_absolute_error: 0.3362 - val_loss: 0.1795 - val_mean_absolute_error: 0.3382\n",
      "---------------------------------------------------------------------------------------------------------\n",
      "Running model for... Hopper-v2\n",
      "returns [388.2422745725005, 392.5777027153638, 1026.531159363883, 399.1440522935604, 391.29263035516396, 380.65895846097027, 380.17688302559066, 448.801888277772, 382.6035272735681, 439.6309310898492, 394.78541945973245, 386.88349092879355, 519.9255673788151, 395.3786171976868, 376.6031776626222, 384.66521133260204, 381.81182345622955, 430.91173298389134, 381.2611760608152, 373.73025636765686]\n",
      "mean return 432.7808240128534\n",
      "std of return 140.36636409631546\n",
      "---------------------------------------------------------------------------------------------------------\n",
      "Comparing Walker2d-v2 to expert.\n",
      "Summary statistics for: Walker2d-v2\n",
      "                     expert     predict\n",
      "mean reward     5527.092681  432.780824\n",
      "std reward        52.584267  140.366364\n",
      "% full rollout     1.000000    0.253050\n",
      "---------------------------------------------------------------------------------------------------------\n",
      "Humanoid-v2 Policy Data Loaded\n",
      "Creating model for... Humanoid-v2\n",
      "---------------------------------------------------------------------------------------------------------\n",
      "Fitting model for... Humanoid-v2\n",
      "Train on 18000 samples, validate on 2000 samples\n",
      "Epoch 1/50\n",
      " - 2s - loss: 0.9953 - mean_absolute_error: 0.7807 - val_loss: 0.7323 - val_mean_absolute_error: 0.6702\n",
      "Epoch 2/50\n",
      " - 1s - loss: 0.4506 - mean_absolute_error: 0.5058 - val_loss: 0.3319 - val_mean_absolute_error: 0.4256\n",
      "Epoch 3/50\n",
      " - 1s - loss: 0.2926 - mean_absolute_error: 0.3993 - val_loss: 0.2759 - val_mean_absolute_error: 0.3885\n",
      "Epoch 4/50\n",
      " - 1s - loss: 0.2575 - mean_absolute_error: 0.3785 - val_loss: 0.2497 - val_mean_absolute_error: 0.3752\n",
      "Epoch 5/50\n",
      " - 1s - loss: 0.2389 - mean_absolute_error: 0.3693 - val_loss: 0.2375 - val_mean_absolute_error: 0.3713\n",
      "Epoch 6/50\n",
      " - 2s - loss: 0.2271 - mean_absolute_error: 0.3651 - val_loss: 0.2282 - val_mean_absolute_error: 0.3679\n",
      "Epoch 7/50\n",
      " - 1s - loss: 0.2185 - mean_absolute_error: 0.3622 - val_loss: 0.2198 - val_mean_absolute_error: 0.3637\n",
      "Epoch 8/50\n",
      " - 1s - loss: 0.2115 - mean_absolute_error: 0.3592 - val_loss: 0.2151 - val_mean_absolute_error: 0.3633\n",
      "Epoch 9/50\n",
      " - 1s - loss: 0.2061 - mean_absolute_error: 0.3569 - val_loss: 0.2086 - val_mean_absolute_error: 0.3587\n",
      "Epoch 10/50\n",
      " - 1s - loss: 0.2019 - mean_absolute_error: 0.3542 - val_loss: 0.2041 - val_mean_absolute_error: 0.3564\n",
      "Epoch 11/50\n",
      " - 1s - loss: 0.1986 - mean_absolute_error: 0.3521 - val_loss: 0.2011 - val_mean_absolute_error: 0.3540\n",
      "Epoch 12/50\n",
      " - 1s - loss: 0.1958 - mean_absolute_error: 0.3501 - val_loss: 0.1992 - val_mean_absolute_error: 0.3524\n",
      "Epoch 13/50\n",
      " - 1s - loss: 0.1942 - mean_absolute_error: 0.3487 - val_loss: 0.1976 - val_mean_absolute_error: 0.3522\n",
      "Epoch 14/50\n",
      " - 1s - loss: 0.1924 - mean_absolute_error: 0.3470 - val_loss: 0.1963 - val_mean_absolute_error: 0.3504\n",
      "Epoch 15/50\n",
      " - 1s - loss: 0.1911 - mean_absolute_error: 0.3460 - val_loss: 0.1947 - val_mean_absolute_error: 0.3477\n",
      "Epoch 16/50\n",
      " - 1s - loss: 0.1900 - mean_absolute_error: 0.3448 - val_loss: 0.1947 - val_mean_absolute_error: 0.3481\n",
      "Epoch 17/50\n",
      " - 1s - loss: 0.1892 - mean_absolute_error: 0.3440 - val_loss: 0.1925 - val_mean_absolute_error: 0.3460\n",
      "Epoch 18/50\n",
      " - 1s - loss: 0.1884 - mean_absolute_error: 0.3433 - val_loss: 0.1926 - val_mean_absolute_error: 0.3451\n",
      "Epoch 19/50\n",
      " - 1s - loss: 0.1876 - mean_absolute_error: 0.3425 - val_loss: 0.1926 - val_mean_absolute_error: 0.3456\n",
      "Epoch 20/50\n",
      " - 1s - loss: 0.1873 - mean_absolute_error: 0.3421 - val_loss: 0.1925 - val_mean_absolute_error: 0.3454\n",
      "Epoch 21/50\n",
      " - 1s - loss: 0.1867 - mean_absolute_error: 0.3418 - val_loss: 0.1902 - val_mean_absolute_error: 0.3434\n",
      "Epoch 22/50\n",
      " - 1s - loss: 0.1864 - mean_absolute_error: 0.3414 - val_loss: 0.1910 - val_mean_absolute_error: 0.3434\n",
      "Epoch 23/50\n",
      " - 1s - loss: 0.1859 - mean_absolute_error: 0.3411 - val_loss: 0.1920 - val_mean_absolute_error: 0.3466\n",
      "Epoch 24/50\n",
      " - 1s - loss: 0.1856 - mean_absolute_error: 0.3408 - val_loss: 0.1921 - val_mean_absolute_error: 0.3441\n",
      "Epoch 25/50\n",
      " - 1s - loss: 0.1852 - mean_absolute_error: 0.3405 - val_loss: 0.1899 - val_mean_absolute_error: 0.3442\n",
      "Epoch 26/50\n",
      " - 2s - loss: 0.1853 - mean_absolute_error: 0.3407 - val_loss: 0.1897 - val_mean_absolute_error: 0.3429\n",
      "Epoch 27/50\n",
      " - 1s - loss: 0.1849 - mean_absolute_error: 0.3401 - val_loss: 0.1918 - val_mean_absolute_error: 0.3451\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28/50\n",
      " - 1s - loss: 0.1844 - mean_absolute_error: 0.3398 - val_loss: 0.1887 - val_mean_absolute_error: 0.3426\n",
      "Epoch 29/50\n",
      " - 1s - loss: 0.1844 - mean_absolute_error: 0.3398 - val_loss: 0.1910 - val_mean_absolute_error: 0.3430\n",
      "Epoch 30/50\n",
      " - 1s - loss: 0.1843 - mean_absolute_error: 0.3397 - val_loss: 0.1879 - val_mean_absolute_error: 0.3415\n",
      "Epoch 31/50\n",
      " - 1s - loss: 0.1840 - mean_absolute_error: 0.3393 - val_loss: 0.1897 - val_mean_absolute_error: 0.3442\n",
      "Epoch 32/50\n",
      " - 1s - loss: 0.1840 - mean_absolute_error: 0.3395 - val_loss: 0.1883 - val_mean_absolute_error: 0.3420\n",
      "Epoch 33/50\n",
      " - 2s - loss: 0.1835 - mean_absolute_error: 0.3391 - val_loss: 0.1889 - val_mean_absolute_error: 0.3412\n",
      "Epoch 34/50\n",
      " - 1s - loss: 0.1836 - mean_absolute_error: 0.3390 - val_loss: 0.1890 - val_mean_absolute_error: 0.3434\n",
      "Epoch 35/50\n",
      " - 1s - loss: 0.1834 - mean_absolute_error: 0.3391 - val_loss: 0.1885 - val_mean_absolute_error: 0.3409\n",
      "Epoch 36/50\n",
      " - 1s - loss: 0.1829 - mean_absolute_error: 0.3386 - val_loss: 0.1882 - val_mean_absolute_error: 0.3421\n",
      "Epoch 37/50\n",
      " - 1s - loss: 0.1832 - mean_absolute_error: 0.3388 - val_loss: 0.1878 - val_mean_absolute_error: 0.3410\n",
      "Epoch 38/50\n",
      " - 1s - loss: 0.1830 - mean_absolute_error: 0.3387 - val_loss: 0.1871 - val_mean_absolute_error: 0.3409\n",
      "Epoch 39/50\n",
      " - 1s - loss: 0.1828 - mean_absolute_error: 0.3383 - val_loss: 0.1872 - val_mean_absolute_error: 0.3410\n",
      "Epoch 40/50\n",
      " - 1s - loss: 0.1826 - mean_absolute_error: 0.3382 - val_loss: 0.1877 - val_mean_absolute_error: 0.3411\n",
      "Epoch 41/50\n",
      " - 1s - loss: 0.1826 - mean_absolute_error: 0.3385 - val_loss: 0.1873 - val_mean_absolute_error: 0.3412\n",
      "Epoch 42/50\n",
      " - 1s - loss: 0.1824 - mean_absolute_error: 0.3381 - val_loss: 0.1870 - val_mean_absolute_error: 0.3406\n",
      "Epoch 43/50\n",
      " - 1s - loss: 0.1826 - mean_absolute_error: 0.3383 - val_loss: 0.1872 - val_mean_absolute_error: 0.3404\n",
      "Epoch 44/50\n",
      " - 1s - loss: 0.1824 - mean_absolute_error: 0.3382 - val_loss: 0.1863 - val_mean_absolute_error: 0.3404\n",
      "Epoch 45/50\n",
      " - 1s - loss: 0.1824 - mean_absolute_error: 0.3379 - val_loss: 0.1874 - val_mean_absolute_error: 0.3414\n",
      "Epoch 46/50\n",
      " - 1s - loss: 0.1821 - mean_absolute_error: 0.3378 - val_loss: 0.1869 - val_mean_absolute_error: 0.3414\n",
      "Epoch 47/50\n",
      " - 1s - loss: 0.1822 - mean_absolute_error: 0.3377 - val_loss: 0.1861 - val_mean_absolute_error: 0.3403\n",
      "Epoch 48/50\n",
      " - 1s - loss: 0.1820 - mean_absolute_error: 0.3378 - val_loss: 0.1860 - val_mean_absolute_error: 0.3403\n",
      "Epoch 49/50\n",
      " - 2s - loss: 0.1820 - mean_absolute_error: 0.3378 - val_loss: 0.1872 - val_mean_absolute_error: 0.3404\n",
      "Epoch 50/50\n",
      " - 2s - loss: 0.1818 - mean_absolute_error: 0.3375 - val_loss: 0.1862 - val_mean_absolute_error: 0.3401\n",
      "---------------------------------------------------------------------------------------------------------\n",
      "Running model for... Humanoid-v2\n",
      "returns [1206.898571707606, 762.3080296313493, 754.6093721723593, 2341.192163617365, 1746.439954658906, 1201.9074469286297, 1111.2249498313242, 897.9986148603408, 760.4725576528225, 744.788570530291, 1228.2778867808863, 1361.8754128508722, 1196.1572636157816, 748.9697162070267, 754.2617445918945, 1485.8891627670266, 1773.6744201613578, 752.4445095519543, 1185.716383146749, 1213.4727068045986]\n",
      "mean return 1161.428971903457\n",
      "std of return 418.407876938835\n",
      "---------------------------------------------------------------------------------------------------------\n",
      "Comparing Walker2d-v2 to expert.\n",
      "Summary statistics for: Walker2d-v2\n",
      "                     expert      predict\n",
      "mean reward     5527.092681  1161.428972\n",
      "std reward        52.584267   418.407877\n",
      "% full rollout     1.000000     0.545455\n",
      "---------------------------------------------------------------------------------------------------------\n",
      "Reacher-v2 Policy Data Loaded\n",
      "Creating model for... Reacher-v2\n",
      "---------------------------------------------------------------------------------------------------------\n",
      "Fitting model for... Reacher-v2\n",
      "Train on 18000 samples, validate on 2000 samples\n",
      "Epoch 1/50\n",
      " - 2s - loss: 0.9477 - mean_absolute_error: 0.7703 - val_loss: 0.7064 - val_mean_absolute_error: 0.6615\n",
      "Epoch 2/50\n",
      " - 1s - loss: 0.4711 - mean_absolute_error: 0.5204 - val_loss: 0.3585 - val_mean_absolute_error: 0.4562\n",
      "Epoch 3/50\n",
      " - 1s - loss: 0.3226 - mean_absolute_error: 0.4285 - val_loss: 0.2952 - val_mean_absolute_error: 0.4077\n",
      "Epoch 4/50\n",
      " - 1s - loss: 0.2853 - mean_absolute_error: 0.3962 - val_loss: 0.2755 - val_mean_absolute_error: 0.3873\n",
      "Epoch 5/50\n",
      " - 1s - loss: 0.2686 - mean_absolute_error: 0.3809 - val_loss: 0.2603 - val_mean_absolute_error: 0.3749\n",
      "Epoch 6/50\n",
      " - 1s - loss: 0.2564 - mean_absolute_error: 0.3750 - val_loss: 0.2508 - val_mean_absolute_error: 0.3731\n",
      "Epoch 7/50\n",
      " - 1s - loss: 0.2471 - mean_absolute_error: 0.3733 - val_loss: 0.2428 - val_mean_absolute_error: 0.3751\n",
      "Epoch 8/50\n",
      " - 1s - loss: 0.2372 - mean_absolute_error: 0.3718 - val_loss: 0.2266 - val_mean_absolute_error: 0.3686\n",
      "Epoch 9/50\n",
      " - 1s - loss: 0.2228 - mean_absolute_error: 0.3672 - val_loss: 0.2141 - val_mean_absolute_error: 0.3642\n",
      "Epoch 10/50\n",
      " - 1s - loss: 0.2120 - mean_absolute_error: 0.3606 - val_loss: 0.2056 - val_mean_absolute_error: 0.3584\n",
      "Epoch 11/50\n",
      " - 1s - loss: 0.2048 - mean_absolute_error: 0.3553 - val_loss: 0.1999 - val_mean_absolute_error: 0.3527\n",
      "Epoch 12/50\n",
      " - 1s - loss: 0.2001 - mean_absolute_error: 0.3519 - val_loss: 0.1963 - val_mean_absolute_error: 0.3503\n",
      "Epoch 13/50\n",
      " - 1s - loss: 0.1963 - mean_absolute_error: 0.3493 - val_loss: 0.1929 - val_mean_absolute_error: 0.3467\n",
      "Epoch 14/50\n",
      " - 1s - loss: 0.1940 - mean_absolute_error: 0.3476 - val_loss: 0.1920 - val_mean_absolute_error: 0.3467\n",
      "Epoch 15/50\n",
      " - 1s - loss: 0.1922 - mean_absolute_error: 0.3465 - val_loss: 0.1895 - val_mean_absolute_error: 0.3439\n",
      "Epoch 16/50\n",
      " - 1s - loss: 0.1904 - mean_absolute_error: 0.3455 - val_loss: 0.1886 - val_mean_absolute_error: 0.3444\n",
      "Epoch 17/50\n",
      " - 1s - loss: 0.1888 - mean_absolute_error: 0.3446 - val_loss: 0.1869 - val_mean_absolute_error: 0.3434\n",
      "Epoch 18/50\n",
      " - 1s - loss: 0.1877 - mean_absolute_error: 0.3439 - val_loss: 0.1860 - val_mean_absolute_error: 0.3428\n",
      "Epoch 19/50\n",
      " - 1s - loss: 0.1867 - mean_absolute_error: 0.3430 - val_loss: 0.1859 - val_mean_absolute_error: 0.3414\n",
      "Epoch 20/50\n",
      " - 1s - loss: 0.1857 - mean_absolute_error: 0.3419 - val_loss: 0.1845 - val_mean_absolute_error: 0.3409\n",
      "Epoch 21/50\n",
      " - 1s - loss: 0.1853 - mean_absolute_error: 0.3417 - val_loss: 0.1834 - val_mean_absolute_error: 0.3403\n",
      "Epoch 22/50\n",
      " - 1s - loss: 0.1849 - mean_absolute_error: 0.3414 - val_loss: 0.1825 - val_mean_absolute_error: 0.3389\n",
      "Epoch 23/50\n",
      " - 1s - loss: 0.1845 - mean_absolute_error: 0.3411 - val_loss: 0.1832 - val_mean_absolute_error: 0.3393\n",
      "Epoch 24/50\n",
      " - 1s - loss: 0.1840 - mean_absolute_error: 0.3407 - val_loss: 0.1844 - val_mean_absolute_error: 0.3395\n",
      "Epoch 25/50\n",
      " - 1s - loss: 0.1834 - mean_absolute_error: 0.3401 - val_loss: 0.1840 - val_mean_absolute_error: 0.3408\n",
      "Epoch 26/50\n",
      " - 1s - loss: 0.1834 - mean_absolute_error: 0.3400 - val_loss: 0.1820 - val_mean_absolute_error: 0.3404\n",
      "Epoch 27/50\n",
      " - 1s - loss: 0.1831 - mean_absolute_error: 0.3399 - val_loss: 0.1820 - val_mean_absolute_error: 0.3376\n",
      "Epoch 28/50\n",
      " - 1s - loss: 0.1826 - mean_absolute_error: 0.3391 - val_loss: 0.1817 - val_mean_absolute_error: 0.3378\n",
      "Epoch 29/50\n",
      " - 1s - loss: 0.1825 - mean_absolute_error: 0.3390 - val_loss: 0.1809 - val_mean_absolute_error: 0.3376\n",
      "Epoch 30/50\n",
      " - 1s - loss: 0.1824 - mean_absolute_error: 0.3390 - val_loss: 0.1815 - val_mean_absolute_error: 0.3382\n",
      "Epoch 31/50\n",
      " - 1s - loss: 0.1821 - mean_absolute_error: 0.3387 - val_loss: 0.1814 - val_mean_absolute_error: 0.3383\n",
      "Epoch 32/50\n",
      " - 1s - loss: 0.1817 - mean_absolute_error: 0.3383 - val_loss: 0.1815 - val_mean_absolute_error: 0.3380\n",
      "Epoch 33/50\n",
      " - 1s - loss: 0.1817 - mean_absolute_error: 0.3384 - val_loss: 0.1815 - val_mean_absolute_error: 0.3384\n",
      "Epoch 34/50\n",
      " - 1s - loss: 0.1815 - mean_absolute_error: 0.3381 - val_loss: 0.1813 - val_mean_absolute_error: 0.3394\n",
      "Epoch 35/50\n",
      " - 1s - loss: 0.1812 - mean_absolute_error: 0.3378 - val_loss: 0.1809 - val_mean_absolute_error: 0.3378\n",
      "Epoch 36/50\n",
      " - 1s - loss: 0.1812 - mean_absolute_error: 0.3378 - val_loss: 0.1809 - val_mean_absolute_error: 0.3378\n",
      "Epoch 37/50\n",
      " - 1s - loss: 0.1810 - mean_absolute_error: 0.3378 - val_loss: 0.1805 - val_mean_absolute_error: 0.3378\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 38/50\n",
      " - 1s - loss: 0.1811 - mean_absolute_error: 0.3377 - val_loss: 0.1806 - val_mean_absolute_error: 0.3375\n",
      "Epoch 39/50\n",
      " - 1s - loss: 0.1809 - mean_absolute_error: 0.3376 - val_loss: 0.1799 - val_mean_absolute_error: 0.3368\n",
      "Epoch 40/50\n",
      " - 1s - loss: 0.1808 - mean_absolute_error: 0.3376 - val_loss: 0.1804 - val_mean_absolute_error: 0.3370\n",
      "Epoch 41/50\n",
      " - 1s - loss: 0.1806 - mean_absolute_error: 0.3375 - val_loss: 0.1802 - val_mean_absolute_error: 0.3372\n",
      "Epoch 42/50\n",
      " - 1s - loss: 0.1805 - mean_absolute_error: 0.3373 - val_loss: 0.1802 - val_mean_absolute_error: 0.3379\n",
      "Epoch 43/50\n",
      " - 1s - loss: 0.1803 - mean_absolute_error: 0.3368 - val_loss: 0.1815 - val_mean_absolute_error: 0.3377\n",
      "Epoch 44/50\n",
      " - 1s - loss: 0.1801 - mean_absolute_error: 0.3369 - val_loss: 0.1802 - val_mean_absolute_error: 0.3374\n",
      "Epoch 45/50\n",
      " - 1s - loss: 0.1803 - mean_absolute_error: 0.3373 - val_loss: 0.1796 - val_mean_absolute_error: 0.3362\n",
      "Epoch 46/50\n",
      " - 1s - loss: 0.1800 - mean_absolute_error: 0.3367 - val_loss: 0.1795 - val_mean_absolute_error: 0.3366\n",
      "Epoch 47/50\n",
      " - 1s - loss: 0.1799 - mean_absolute_error: 0.3370 - val_loss: 0.1809 - val_mean_absolute_error: 0.3373\n",
      "Epoch 48/50\n",
      " - 1s - loss: 0.1800 - mean_absolute_error: 0.3369 - val_loss: 0.1789 - val_mean_absolute_error: 0.3352\n",
      "Epoch 49/50\n",
      " - 1s - loss: 0.1798 - mean_absolute_error: 0.3367 - val_loss: 0.1810 - val_mean_absolute_error: 0.3376\n",
      "Epoch 50/50\n",
      " - 1s - loss: 0.1798 - mean_absolute_error: 0.3366 - val_loss: 0.1806 - val_mean_absolute_error: 0.3378\n",
      "---------------------------------------------------------------------------------------------------------\n",
      "Running model for... Reacher-v2\n",
      "returns [3180.9530777628916, 2136.5086709788166, 3437.4841313894335, 1096.748975885026, 1081.0060844667587, 1495.4955569775584, 2031.7333114956284, 1318.1518711540075, 1345.0847468137097, 1101.4208018616423, 1067.6515274459748, 1773.8716785589263, 1531.7856813293283, 3293.9862906112226, 2151.3294029010376, 1261.9153977522626, 1749.403082173977, 1270.8029392953265, 1266.7830779383585, 1290.82684417295]\n",
      "mean return 1744.1471575482417\n",
      "std of return 734.9970882541587\n",
      "---------------------------------------------------------------------------------------------------------\n",
      "Comparing Walker2d-v2 to expert.\n",
      "Summary statistics for: Walker2d-v2\n",
      "                     expert      predict\n",
      "mean reward     5527.092681  1744.147158\n",
      "std reward        52.584267   734.997088\n",
      "% full rollout     1.000000     0.575150\n",
      "---------------------------------------------------------------------------------------------------------\n",
      "Walker2d-v2 Policy Data Loaded\n",
      "Creating model for... Walker2d-v2\n",
      "---------------------------------------------------------------------------------------------------------\n",
      "Fitting model for... Walker2d-v2\n",
      "Train on 18000 samples, validate on 2000 samples\n",
      "Epoch 1/50\n",
      " - 2s - loss: 1.0400 - mean_absolute_error: 0.8044 - val_loss: 0.6611 - val_mean_absolute_error: 0.6457\n",
      "Epoch 2/50\n",
      " - 1s - loss: 0.5392 - mean_absolute_error: 0.5745 - val_loss: 0.4568 - val_mean_absolute_error: 0.5207\n",
      "Epoch 3/50\n",
      " - 1s - loss: 0.4040 - mean_absolute_error: 0.4826 - val_loss: 0.3449 - val_mean_absolute_error: 0.4416\n",
      "Epoch 4/50\n",
      " - 1s - loss: 0.3157 - mean_absolute_error: 0.4172 - val_loss: 0.2751 - val_mean_absolute_error: 0.3891\n",
      "Epoch 5/50\n",
      " - 1s - loss: 0.2645 - mean_absolute_error: 0.3855 - val_loss: 0.2452 - val_mean_absolute_error: 0.3743\n",
      "Epoch 6/50\n",
      " - 1s - loss: 0.2387 - mean_absolute_error: 0.3726 - val_loss: 0.2254 - val_mean_absolute_error: 0.3646\n",
      "Epoch 7/50\n",
      " - 1s - loss: 0.2261 - mean_absolute_error: 0.3662 - val_loss: 0.2163 - val_mean_absolute_error: 0.3603\n",
      "Epoch 8/50\n",
      " - 1s - loss: 0.2174 - mean_absolute_error: 0.3617 - val_loss: 0.2085 - val_mean_absolute_error: 0.3568\n",
      "Epoch 9/50\n",
      " - 1s - loss: 0.2111 - mean_absolute_error: 0.3580 - val_loss: 0.2030 - val_mean_absolute_error: 0.3538\n",
      "Epoch 10/50\n",
      " - 1s - loss: 0.2042 - mean_absolute_error: 0.3548 - val_loss: 0.1963 - val_mean_absolute_error: 0.3489\n",
      "Epoch 11/50\n",
      " - 1s - loss: 0.1989 - mean_absolute_error: 0.3520 - val_loss: 0.1936 - val_mean_absolute_error: 0.3483\n",
      "Epoch 12/50\n",
      " - 1s - loss: 0.1958 - mean_absolute_error: 0.3504 - val_loss: 0.1926 - val_mean_absolute_error: 0.3472\n",
      "Epoch 13/50\n",
      " - 1s - loss: 0.1936 - mean_absolute_error: 0.3491 - val_loss: 0.1906 - val_mean_absolute_error: 0.3454\n",
      "Epoch 14/50\n",
      " - 1s - loss: 0.1920 - mean_absolute_error: 0.3477 - val_loss: 0.1883 - val_mean_absolute_error: 0.3448\n",
      "Epoch 15/50\n",
      " - 1s - loss: 0.1908 - mean_absolute_error: 0.3467 - val_loss: 0.1869 - val_mean_absolute_error: 0.3438\n",
      "Epoch 16/50\n",
      " - 1s - loss: 0.1893 - mean_absolute_error: 0.3457 - val_loss: 0.1868 - val_mean_absolute_error: 0.3437\n",
      "Epoch 17/50\n",
      " - 1s - loss: 0.1884 - mean_absolute_error: 0.3447 - val_loss: 0.1878 - val_mean_absolute_error: 0.3440\n",
      "Epoch 18/50\n",
      " - 1s - loss: 0.1878 - mean_absolute_error: 0.3441 - val_loss: 0.1872 - val_mean_absolute_error: 0.3440\n",
      "Epoch 19/50\n",
      " - 1s - loss: 0.1872 - mean_absolute_error: 0.3436 - val_loss: 0.1855 - val_mean_absolute_error: 0.3421\n",
      "Epoch 20/50\n",
      " - 1s - loss: 0.1865 - mean_absolute_error: 0.3430 - val_loss: 0.1876 - val_mean_absolute_error: 0.3422\n",
      "Epoch 21/50\n",
      " - 1s - loss: 0.1860 - mean_absolute_error: 0.3424 - val_loss: 0.1833 - val_mean_absolute_error: 0.3400\n",
      "Epoch 22/50\n",
      " - 1s - loss: 0.1858 - mean_absolute_error: 0.3420 - val_loss: 0.1847 - val_mean_absolute_error: 0.3410\n",
      "Epoch 23/50\n",
      " - 1s - loss: 0.1850 - mean_absolute_error: 0.3414 - val_loss: 0.1849 - val_mean_absolute_error: 0.3411\n",
      "Epoch 24/50\n",
      " - 1s - loss: 0.1844 - mean_absolute_error: 0.3406 - val_loss: 0.1831 - val_mean_absolute_error: 0.3397\n",
      "Epoch 25/50\n",
      " - 1s - loss: 0.1842 - mean_absolute_error: 0.3406 - val_loss: 0.1834 - val_mean_absolute_error: 0.3392\n",
      "Epoch 26/50\n",
      " - 1s - loss: 0.1841 - mean_absolute_error: 0.3403 - val_loss: 0.1823 - val_mean_absolute_error: 0.3387\n",
      "Epoch 27/50\n",
      " - 1s - loss: 0.1837 - mean_absolute_error: 0.3401 - val_loss: 0.1819 - val_mean_absolute_error: 0.3382\n",
      "Epoch 28/50\n",
      " - 1s - loss: 0.1835 - mean_absolute_error: 0.3399 - val_loss: 0.1814 - val_mean_absolute_error: 0.3372\n",
      "Epoch 29/50\n",
      " - 1s - loss: 0.1831 - mean_absolute_error: 0.3393 - val_loss: 0.1814 - val_mean_absolute_error: 0.3378\n",
      "Epoch 30/50\n",
      " - 1s - loss: 0.1827 - mean_absolute_error: 0.3391 - val_loss: 0.1814 - val_mean_absolute_error: 0.3375\n",
      "Epoch 31/50\n",
      " - 1s - loss: 0.1826 - mean_absolute_error: 0.3389 - val_loss: 0.1805 - val_mean_absolute_error: 0.3359\n",
      "Epoch 32/50\n",
      " - 1s - loss: 0.1823 - mean_absolute_error: 0.3387 - val_loss: 0.1816 - val_mean_absolute_error: 0.3386\n",
      "Epoch 33/50\n",
      " - 1s - loss: 0.1822 - mean_absolute_error: 0.3386 - val_loss: 0.1815 - val_mean_absolute_error: 0.3382\n",
      "Epoch 34/50\n",
      " - 1s - loss: 0.1822 - mean_absolute_error: 0.3386 - val_loss: 0.1807 - val_mean_absolute_error: 0.3373\n",
      "Epoch 35/50\n",
      " - 1s - loss: 0.1818 - mean_absolute_error: 0.3383 - val_loss: 0.1818 - val_mean_absolute_error: 0.3385\n",
      "Epoch 36/50\n",
      " - 1s - loss: 0.1816 - mean_absolute_error: 0.3380 - val_loss: 0.1802 - val_mean_absolute_error: 0.3375\n",
      "Epoch 37/50\n",
      " - 1s - loss: 0.1816 - mean_absolute_error: 0.3380 - val_loss: 0.1804 - val_mean_absolute_error: 0.3373\n",
      "Epoch 38/50\n",
      " - 1s - loss: 0.1814 - mean_absolute_error: 0.3379 - val_loss: 0.1798 - val_mean_absolute_error: 0.3371\n",
      "Epoch 39/50\n",
      " - 1s - loss: 0.1811 - mean_absolute_error: 0.3376 - val_loss: 0.1796 - val_mean_absolute_error: 0.3358\n",
      "Epoch 40/50\n",
      " - 1s - loss: 0.1810 - mean_absolute_error: 0.3375 - val_loss: 0.1804 - val_mean_absolute_error: 0.3372\n",
      "Epoch 41/50\n",
      " - 1s - loss: 0.1810 - mean_absolute_error: 0.3375 - val_loss: 0.1810 - val_mean_absolute_error: 0.3366\n",
      "Epoch 42/50\n",
      " - 1s - loss: 0.1807 - mean_absolute_error: 0.3370 - val_loss: 0.1802 - val_mean_absolute_error: 0.3378\n",
      "Epoch 43/50\n",
      " - 1s - loss: 0.1807 - mean_absolute_error: 0.3372 - val_loss: 0.1789 - val_mean_absolute_error: 0.3361\n",
      "Epoch 44/50\n",
      " - 1s - loss: 0.1805 - mean_absolute_error: 0.3370 - val_loss: 0.1793 - val_mean_absolute_error: 0.3362\n",
      "Epoch 45/50\n",
      " - 1s - loss: 0.1804 - mean_absolute_error: 0.3369 - val_loss: 0.1787 - val_mean_absolute_error: 0.3352\n",
      "Epoch 46/50\n",
      " - 1s - loss: 0.1803 - mean_absolute_error: 0.3367 - val_loss: 0.1788 - val_mean_absolute_error: 0.3349\n",
      "Epoch 47/50\n",
      " - 1s - loss: 0.1803 - mean_absolute_error: 0.3368 - val_loss: 0.1795 - val_mean_absolute_error: 0.3351\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 48/50\n",
      " - 1s - loss: 0.1801 - mean_absolute_error: 0.3366 - val_loss: 0.1794 - val_mean_absolute_error: 0.3361\n",
      "Epoch 49/50\n",
      " - 1s - loss: 0.1801 - mean_absolute_error: 0.3367 - val_loss: 0.1803 - val_mean_absolute_error: 0.3369\n",
      "Epoch 50/50\n",
      " - 1s - loss: 0.1801 - mean_absolute_error: 0.3366 - val_loss: 0.1787 - val_mean_absolute_error: 0.3359\n",
      "---------------------------------------------------------------------------------------------------------\n",
      "Running model for... Walker2d-v2\n",
      "returns [495.9823004293302, 1032.8941219310245, 1037.366490633943, 1037.46990671696, 1035.2419977414654, 1034.2657985363358, 1040.3339929588958, 1035.2732704691675, 463.78894321124, 1041.8043697176386, 1036.2180229548624, 1034.3206955629996, 471.08206619439034, 1033.3647602122662, 489.18579505689564, 1034.1038341740057, 1035.1245480571554, 1039.2934878936978, 1045.9803786331033, 1032.1634804146797]\n",
      "mean return 925.2629130750029\n",
      "std of return 222.72608897730007\n",
      "---------------------------------------------------------------------------------------------------------\n",
      "Comparing Walker2d-v2 to expert.\n",
      "Summary statistics for: Walker2d-v2\n",
      "                     expert     predict\n",
      "mean reward     5527.092681  925.262913\n",
      "std reward        52.584267  222.726089\n",
      "% full rollout     1.000000    0.856600\n"
     ]
    }
   ],
   "source": [
    "for roll_out in roll_outs:\n",
    "    # load policy data\n",
    "    data = pickle.load(open('expert_data/'+ roll_out + '.pkl', 'rb'))\n",
    "    print('---------------------------------------------------------------------------------------------------------')\n",
    "    print(roll_out + ' Policy Data Loaded')\n",
    "    print('Creating model for... ' + roll_out)\n",
    "    \n",
    "    \n",
    "    input_dim = env.observation_space.shape[0]\n",
    "    output_dim = env.action_space.shape[0]\n",
    "\n",
    "    # set up sequential model\n",
    "    model = Sequential()\n",
    "    model.add(Dense(64, input_shape=(input_dim,), activation='relu'))\n",
    "    model.add(Dense(3, activation='relu'))\n",
    "    model.add(Dense(output_dim))\n",
    "    model.compile(optimizer='adam', loss='mse', metrics=['mae'])\n",
    "\n",
    "    # randomize the data\n",
    "\n",
    "    x, y = shuffle(data['observations'], data['actions'].reshape(-1, output_dim))\n",
    "\n",
    "    print('---------------------------------------------------------------------------------------------------------')    \n",
    "    print('Fitting model for... ' + roll_out)    \n",
    "    # Train the model, iterating on the data in batches of 32 samples\n",
    "    model.fit(x, y, validation_split=0.1, epochs=50, batch_size=32, verbose=2)\n",
    "\n",
    "    print('---------------------------------------------------------------------------------------------------------') \n",
    "    print('Running model for... ' + roll_out)    \n",
    "    # run the model and save for comparison\n",
    "    observations = []\n",
    "    actions = []\n",
    "    returns = []\n",
    "    step_count = []\n",
    "    \n",
    "    for i in range(num_rollouts):\n",
    "        obs = env.reset()\n",
    "        done = False\n",
    "        totalr = 0.\n",
    "        steps = 0\n",
    "        while not done:\n",
    "            action = model.predict(obs[None,:])\n",
    "            observations.append(obs)\n",
    "            actions.append(action)\n",
    "            obs, r, done, _ = env.step(action)\n",
    "            totalr += r\n",
    "            steps += 1\n",
    "            if render:\n",
    "                env.render()\n",
    "                # if steps % 100 == 0: print(\"%i/%i\"%(steps, max_steps))\n",
    "            if steps >= max_steps:\n",
    "                break\n",
    "        returns.append(totalr)\n",
    "        step_count.append(steps)\n",
    "\n",
    "    print('returns', returns)\n",
    "    print('mean return', np.mean(returns))\n",
    "    print('std of return', np.std(returns))\n",
    "\n",
    "    predict_data = {'observations': np.array(observations),\n",
    "                    'actions': np.array(actions),\n",
    "                    'returns': np.array(returns),\n",
    "                    'steps': np.array(step_count)\n",
    "                   }\n",
    "        \n",
    "    # if the predict_data directory doesn't exist, make it\n",
    "    output_dir = 'predict_data'\n",
    "    if not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)   \n",
    "\n",
    "    # store the roll outs in expert_data folder    \n",
    "    for roll_out in roll_outs:\n",
    "            with open(os.path.join('predict_data', roll_out + '.pkl'), 'wb') as f:\n",
    "                pickle.dump(predict_data, f, pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "    print('---------------------------------------------------------------------------------------------------------')\n",
    "    print('Comparing ' + roll_out + ' to expert.') \n",
    "    \n",
    "    expert = pickle.load(open('expert_data/' + roll_out + '.pkl', 'rb'))\n",
    "    predict =pickle.load(open('predict_data/' + roll_out + '.pkl', 'rb'))\n",
    "    \n",
    "    expert_stats = pd.Series({\n",
    "        'mean reward': data['returns'].mean(),\n",
    "        'std reward': data['returns'].std(),\n",
    "        '% full rollout': (data['steps']/data['steps'].max()).mean()\n",
    "    })\n",
    "    predict_stats = pd.Series({\n",
    "        'mean reward': predict_data['returns'].mean(),\n",
    "        'std reward': predict_data['returns'].std(),\n",
    "        '% full rollout': (predict_data['steps']/predict_data['steps'].max()).mean()\n",
    "    })\n",
    "    \n",
    "    df = pd.DataFrame({\n",
    "        'expert': expert_stats,\n",
    "        'predict': predict_stats\n",
    "    })\n",
    "    \n",
    "    print('Summary statistics for: ' + roll_out)\n",
    "    print(df)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
